distribute_crawler
==================

使用scrapy,redis, mongodb,graphite实现的一个分布式网络爬虫,底层存储mongodb集群,分布式使用redis实现,
爬虫状态显示使用graphite实现。

这个工程是我对垂直搜索引擎中分布式网络爬虫的探索实现，它包含一个针对http://www.woaidu.org/ 网站的spider，
将其网站的书名，作者，书籍封面图片，书籍概要，原始网址链接，书籍下载信息和书籍爬取到本地：
* 分布式使用redis实现，redis中存储了工程的request，stats信息，能够对各个机器上的爬虫实现集中管理，这样可以
解决爬虫的性能瓶颈，利用redis的高效和易于扩展能够轻松实现高效率下载：当redis存储或者访问速度遇到瓶颈时，可以
通过增大redis集群数和爬虫集群数量改善。
* 底层存储实现了两种方式：
  * 将书名，作者，书籍封面图片文件系统路径，书籍概要，原始网址链接，书籍下载信息，书籍文件系统路径保存到mongodb
中，此时mongodb使用单个服务器,对图片采用图片的url的hash值作为文件名进行存储，同时可以定制生成各种大小尺寸的缩略
图，对文件动态获得文件名，将其下载到本地，存储方式和图片类似，这样在每次下载之前会检查图片和文件是否曾经下载，对
已经下载的不再下载；
  * 将书名，作者，书籍封面图片文件系统路径，书籍概要，原始网址链接，书籍下载信息，书籍保存到mongodb中，此时mongodb
采用mongodb集群进行存储，片键和索引的选择请看代码，文件采用mongodb的gridfs存储

特色：
* 底层存储
